import os
import asyncio
from dotenv import load_dotenv
from typing import Optional
from openai import AsyncOpenAI

# --- Import agents ---
from agents.stock_agent import StockAgent
from agents.advice_agent import analyze_stock
from agents.news_agent import NewsAgent

# --- Import RAG + Memory ---
from rag.rag_engine import RagEngine
from memory.conversation_memory import ConversationMemory
from tools.rag_chroma import RAGChroma


class OrchestratorAgent:
    def __init__(
        self,
        model_name: str = "meta-llama/llama-4-scout-17b-16e-instruct",
        rag_engine: Optional[RagEngine] = None,
        memory: Optional[ConversationMemory] = None,
    ):
        """Kh·ªüi t·∫°o Orchestrator Agent"""
        load_dotenv()
        self.model_name = model_name
        self.api_key = os.getenv("GROQ_API_KEY")

        if not self.api_key:
            raise ValueError("‚ùå Thi·∫øu GROQ_API_KEY trong .env")

        # --- Kh·ªüi t·∫°o client LLM ---
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url="https://api.groq.com/openai/v1"
        )

        # --- C√°c agent ph·ª• ---
        self.stock_agent = StockAgent()
        self.news_agent = NewsAgent()
        self.rag_engine = rag_engine or RagEngine()
        self.memory = memory or ConversationMemory()

        # --- Ki·ªÉm tra RAG database ---
        if hasattr(self.rag_engine, "rag_db") and not getattr(self.rag_engine.rag_db, "collection", None):
            print("‚ö†Ô∏è RAG engine ch∆∞a kh·ªüi t·∫°o collection, ƒëang kh·ªüi t·∫°o l·∫°i...")
            self.rag_engine.rag_db = RAGChroma()

    #H√†m g·ªçi LLM Groq async
    async def _call_llm(self, prompt: str) -> str:
        """G·ªçi LLM Groq v·ªõi prompt truy·ªÅn v√†o"""
        try:
            resp = await self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=500,
            )
            return resp.choices[0].message.content.strip()
        except Exception as e:
            print("[WARN] Groq LLM call failed:", e)
            return ""

    # H√†m ch√≠nh x·ª≠ l√Ω query t·ª´ user
    async def handle_query(self, query: str, user_id: str = "default") -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng"""

        # L∆∞u h·ªôi tho·∫°i user
        self.memory.add_message(user_id, "user", query)

        # L·∫•y l·∫°i l·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn nh·∫•t
        recent_history = self.memory.get_recent(user_id, n=6)
        conversation_context = "\n".join([
            f"{m['role']}: {m['text']}" for m in recent_history
        ])

        # G·ªçi LLM ƒë·ªÉ x√°c ƒë·ªãnh intent
        routing_prompt = f"""
        L·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn ƒë√¢y:
        {conversation_context}

        C√¢u h·ªèi m·ªõi:
        {query}

        H√£y x√°c ƒë·ªãnh lo·∫°i y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng (intent ch√≠nh):
        - N·∫øu h·ªèi v·ªÅ gi√° c·ªï phi·∫øu ‚Üí "price"
        - N·∫øu h·ªèi t∆∞ v·∫•n ƒë·∫ßu t∆∞ ho·∫∑c ph√¢n t√≠ch c·ªï phi·∫øu ‚Üí "advice"
        - N·∫øu h·ªèi tin t·ª©c ho·∫∑c xu h∆∞·ªõng th·ªã tr∆∞·ªùng ‚Üí "news"
        - N·∫øu ch√†o h·ªèi ho·∫∑c tr√≤ chuy·ªán chung ‚Üí "chat"
        Tr·∫£ v·ªÅ ƒë√∫ng 1 t·ª´ trong c√°c lo·∫°i tr√™n.
        """

        try:
            routing_text = await self._call_llm(routing_prompt)
        except Exception:
            routing_text = ""

        rd = (routing_text or "").lower().strip()
        lower = query.lower()

        # X√°c ƒë·ªãnh intent
        if "advice" in rd or any(k in lower for k in ["mua", "b√°n", "ph√¢n t√≠ch", "khuy·∫øn ngh·ªã", "ƒë·∫ßu t∆∞"]):
            intent = "advice_query"
        elif "price" in rd or any(k in lower for k in ["gi√°", "bao nhi√™u", "tƒÉng", "gi·∫£m", "h√¥m nay", "h√¥m qua"]):
            intent = "price_query"
        elif "news" in rd or any(k in lower for k in ["tin t·ª©c", "th·ªã tr∆∞·ªùng", "vƒ© m√¥", "xu h∆∞·ªõng", "b√°o c√°o"]):
            intent = "news_query"
        else:
            intent = "chat"

        # L·∫•y context t·ª´ RAG (n·∫øu c√≥)
        try:
            context_text = self.rag_engine.retrieve_context(query)
            if context_text:
                print(f"üìö RAG context len: {len(context_text)} chars")
        except Exception as e:
            print("[WARN] RAG retrieval failed:", e)
            context_text = ""

        # G·ªçi agent t∆∞∆°ng ·ª©ng
        if intent == "price_query":
            response = self.stock_agent.handle_request(query)

        elif intent == "advice_query":
            response = analyze_stock(query)

        elif intent == "news_query":
            symbol = self.stock_agent.extract_symbol(query)
            if not symbol:
                response = "Kh√¥ng t√¨m th·∫•y m√£ c·ªï phi·∫øu h·ª£p l·ªá trong c√¢u h·ªèi. V√≠ d·ª•: 'tin t·ª©c v·ªÅ FPT'."
            else:
                rag_results = []
                try:
                    rag_results = self.rag_engine.query(query)
                except Exception as e:
                    print("[WARN] RAG query failed:", e)

                if rag_results:
                    print(f"üìö Found {len(rag_results)} results from local RAG DB")
                    response = "\n".join([
                        f"- {r['text']} ({r['metadata'].get('source')}, {r['metadata'].get('date')})"
                        for r in rag_results[:3]
                    ])
                else:
                    print("üåê No local data found ‚Üí crawling news...")
                    data = self.news_agent.run(symbol)
                    if data and "articles" in data:
                        texts = [f"{a['title']} - {a['description']}" for a in data["articles"]]
                        metas = [
                            {
                                "symbol": symbol,
                                "source": a["source"],
                                "url": a["url"],
                                "date": a["date"],
                                "sentiment": a["sentiment"]
                            }
                            for a in data["articles"]
                        ]
                        self.rag_engine.add_documents(texts, metas)
                        print(f"‚úÖ Saved {len(texts)} new articles for {symbol} to RAG")

                    response = data.get("summary", "Kh√¥ng t√¨m th·∫•y tin t·ª©c m·ªõi.")
        else:
            response = "ü§ñ Xin ch√†o! M√¨nh l√† tr·ª£ l√Ω t√†i ch√≠nh. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√° c·ªï phi·∫øu, t∆∞ v·∫•n ƒë·∫ßu t∆∞, ho·∫∑c tin t·ª©c th·ªã tr∆∞·ªùng."

        # T·∫°o prompt t·ªïng h·ª£p ph·∫£n h·ªìi th√¢n thi·ªán
        recent = self.memory.get_recent(user_id, n=6)
        recent_text = "\n".join([f"{m['role']}: {m['text']}" for m in recent])

        final_prompt = f"""
        Ng·ªØ c·∫£nh RAG (n·∫øu c√≥):
        {context_text}

        L·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn nh·∫•t:
        {recent_text}

        Ph·∫£n h·ªìi t·ª´ h·ªá th·ªëng n·ªôi b·ªô:
        {response}

        üëâ H√£y tr·∫£ l·ªùi l·∫°i b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, t·ª± nhi√™n, th√¢n thi·ªán v√† c√≥ th·ªÉ th√™m emoji ph√π h·ª£p.
        """

        try:
            final_text = await self._call_llm(final_prompt)
        except Exception as e:
            print("[WARN] LLM formatting failed:", e)
            final_text = ""

        if not final_text:
            final_text = response if isinstance(response, str) else str(response)

        # L∆∞u ph·∫£n h·ªìi v√†o memory
        self.memory.add_message(user_id, "assistant", final_text)

        return final_text
