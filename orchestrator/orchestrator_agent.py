import os
import asyncio
from dotenv import load_dotenv
from google import genai
from orchestrator.prompt_templates import ORCHESTRATOR_PROMPT
from agents.stock_agent import StockAgent
from agents.advice_agent import analyze_stock


class OrchestratorAgent:
    def __init__(self, model_name: str = "gemini-2.0-flash"):
        """
        Orchestrator ch·ªãu tr√°ch nhi·ªám:
        - ƒê·ªãnh tuy·∫øn c√¢u h·ªèi (routing) b·∫±ng Gemini
        - G·ªçi agent ph√π h·ª£p (stock_agent ho·∫∑c advice_agent)
        - D√πng Gemini format l·∫°i c√¢u tr·∫£ l·ªùi cho th√¢n thi·ªán
        """
        load_dotenv()
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("‚ùå GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p trong .env ho·∫∑c m√¥i tr∆∞·ªùng.")
        
        self.client = genai.Client(api_key=api_key)
        self.model_name = model_name
        self.stock_agent = StockAgent()

    async def _run_llm_stream(self, prompt: str) -> str:
        """
        G·ªçi Gemini API (kh√¥ng d√πng LiteLlm), l·∫•y text t·ª´ stream.
        """
        text_out = ""
        try:
            response = await self.client.aio.models.generate_content(
                model=self.model_name,
                contents=prompt
            )
            if hasattr(response, "text") and response.text:
                text_out = response.text
            elif hasattr(response, "candidates"):
                for cand in response.candidates:
                    if hasattr(cand, "content") and hasattr(cand.content, "parts"):
                        for p in cand.content.parts:
                            if hasattr(p, "text"):
                                text_out += p.text

        except Exception as e:
            print(f"[WARN] LLM call failed: {e}")

        return text_out.strip()

    async def handle_query(self, query: str) -> str:
        """
        Main entry: ƒë·ªãnh tuy·∫øn -> g·ªçi agent -> format -> tr·∫£ v·ªÅ text.
        """
        # üß≠ 1Ô∏è‚É£ Routing prompt
        routing_prompt = ORCHESTRATOR_PROMPT.format(query=query)

        try:
            routing_text = await self._run_llm_stream(routing_prompt)
        except Exception as e:
            print("[WARN] LLM routing failed:", e)
            routing_text = ""

        # ‚úÖ 2Ô∏è‚É£ X√°c ƒë·ªãnh intent
        rd = routing_text.strip().lower()
        if "advice" in rd or "t∆∞ v·∫•n" in rd or "khuy·∫øn ngh·ªã" in rd:
            intent = "advice_query"
        elif "price" in rd or "gi√°" in rd or "price_query" in rd:
            intent = "price_query"
        else:
            lower = query.lower()
            if any(k in lower for k in ["gi√°", "h√¥m nay", "h√¥m qua", "bao nhi√™u", "tƒÉng", "gi·∫£m"]):
                intent = "price_query"
            elif any(k in lower for k in ["c√≥ n√™n", "mua", "b√°n", "ph√¢n t√≠ch", "ƒë·∫ßu t∆∞", "d·ª± ƒëo√°n"]):
                intent = "advice_query"
            else:
                intent = "chat"

        # ‚öôÔ∏è 3Ô∏è‚É£ G·ªçi agent t∆∞∆°ng ·ª©ng
        if intent == "price_query":
            response = self.stock_agent.handle_request(query)
        elif intent == "advice_query":
            response = analyze_stock(query)
        else:
            response = (
                "ü§ñ Xin ch√†o! M√¨nh l√† tr·ª£ l√Ω t√†i ch√≠nh. "
                "B·∫°n c√≥ th·ªÉ h·ªèi m√¨nh v·ªÅ gi√° c·ªï phi·∫øu ho·∫∑c n√™n mua/b√°n m√£ n√†o nh√©!"
            )

        # üí¨ 4Ô∏è‚É£ Format l·∫°i k·∫øt qu·∫£
        final_prompt = f"""
D∆∞·ªõi ƒë√¢y l√† ph·∫£n h·ªìi t·ª´ h·ªá th·ªëng t√†i ch√≠nh:
---
{response}
---
H√£y di·ªÖn gi·∫£i l·∫°i b·∫±ng ti·∫øng Vi·ªát ng·∫Øn g·ªçn, th√¢n thi·ªán, d·ªÖ hi·ªÉu.
Th√™m bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c n·∫øu ph√π h·ª£p.
"""

        try:
            final_text = await self._run_llm_stream(final_prompt)
        except Exception as e:
            print("[WARN] LLM formatting failed:", e)
            return str(response)

        return final_text.strip() or str(response)
